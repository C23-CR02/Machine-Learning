{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rD25N4YEmu6y"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "laKzsfojmpBI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import ast\n",
        "import warnings\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from itertools import groupby\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting JSON Data into CSV"
      ],
      "metadata": {
        "id": "s8dHgdn5J5Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data_json = pd.read_json('response1.json')  # Data output dari Get API"
      ],
      "metadata": {
        "id": "a-rf_9Mk9_UH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_list = []\n",
        "\n",
        "for i in range(len(full_data_json)):\n",
        "  res = full_data_json[\"data\"][i]\n",
        "  res_list.append(res)"
      ],
      "metadata": {
        "id": "d-kRkPlI-phJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_full = pd.DataFrame.from_dict(res_list)[['date', 'hour', 'cpu_used']]\n",
        "json_full['created_at'] = pd.to_datetime(json_full['date'])\n",
        "json_full['created_at'] = json_full['created_at'] + pd.to_timedelta(json_full['hour'], unit='h')\n",
        "json_full['cpu_used'] = json_full['cpu_used'] / 100\n",
        "full_data = json_full[['created_at', 'cpu_used']]"
      ],
      "metadata": {
        "id": "uFBYl_C5HUSI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj58G_ltmpBM"
      },
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r2jMvgJ4mpBM"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(full_data.iloc[:, :-1], full_data.iloc[:, -1], \n",
        "                                                    test_size=0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modeling: ARIMA Univariate Time Series Forecasting"
      ],
      "metadata": {
        "id": "lKwrEiJwf2UD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy54aFxZmpCH"
      },
      "source": [
        "### ARIMA Model Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NITWK9_CmpCH"
      },
      "outputs": [],
      "source": [
        "# Evaluate an ARIMA model for a given order (p,d,q)\n",
        "def evaluate_arima_model(df_train_y, df_test_y, arima_order):\n",
        "    # Prepare training dataset\n",
        "    train_size = int(len(df_train_y))\n",
        "    test_size = int(len(df_test_y))\n",
        "    train, test = df_train_y, df_test_y\n",
        "    # Make predictions\n",
        "    model = ARIMA(df_train_y, order=arima_order)\n",
        "    model_fit = model.fit()\n",
        "    predictions = model_fit.forecast(test_size)\n",
        "    # Calculate out of sample error\n",
        "    rmse = (mean_squared_error(test, predictions))**0.5\n",
        "    mae = mean_absolute_error(test, predictions)\n",
        "    return rmse, mae\n",
        " \n",
        "# Evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(df_train_y, df_test_y, p_values, d_values, q_values):\n",
        "    best_score, best_cfg, best_mae = float(\"inf\"), None, float(\"inf\")\n",
        "    for p in p_values:\n",
        "        for d in d_values:\n",
        "            for q in q_values:\n",
        "                order = (p,d,q)\n",
        "                try:\n",
        "                    rmse, mae = evaluate_arima_model(df_train_y, df_test_y, order)\n",
        "                    if rmse < best_score:\n",
        "                        best_score, best_cfg, best_mae = rmse, order, mae\n",
        "                    print('ARIMA%s RMSE=%.7f MAE=%.7f' % (order,rmse,mae))\n",
        "                except:\n",
        "                    continue\n",
        "    return best_cfg\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfSl-vDmpCH",
        "outputId": "f63b0530-dfab-453e-ffcb-869f6dd94435",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARIMA(1, 0, 1) RMSE=0.0010363 MAE=0.0009478\n",
            "ARIMA(1, 0, 2) RMSE=0.0010172 MAE=0.0009194\n",
            "ARIMA(1, 0, 3) RMSE=0.0009979 MAE=0.0007824\n",
            "ARIMA(1, 0, 4) RMSE=0.0010923 MAE=0.0010166\n",
            "ARIMA(1, 1, 1) RMSE=0.0009585 MAE=0.0007975\n",
            "ARIMA(1, 1, 2) RMSE=0.0009706 MAE=0.0008469\n",
            "ARIMA(1, 1, 3) RMSE=0.0009654 MAE=0.0007928\n",
            "ARIMA(1, 1, 4) RMSE=0.0009077 MAE=0.0007126\n",
            "ARIMA(2, 0, 1) RMSE=0.0011053 MAE=0.0010119\n",
            "ARIMA(2, 0, 2) RMSE=0.0012490 MAE=0.0011525\n",
            "ARIMA(2, 0, 3) RMSE=0.0008586 MAE=0.0007955\n",
            "ARIMA(2, 0, 4) RMSE=0.0010473 MAE=0.0009767\n",
            "ARIMA(2, 1, 1) RMSE=0.0009965 MAE=0.0008620\n",
            "ARIMA(2, 1, 2) RMSE=0.0009734 MAE=0.0008572\n",
            "ARIMA(2, 1, 3) RMSE=0.0009738 MAE=0.0008163\n",
            "ARIMA(2, 1, 4) RMSE=0.0009818 MAE=0.0007930\n",
            "ARIMA(3, 0, 1) RMSE=0.0011258 MAE=0.0010360\n",
            "ARIMA(3, 0, 2) RMSE=0.0010825 MAE=0.0010047\n",
            "ARIMA(3, 0, 3) RMSE=0.0010081 MAE=0.0009340\n",
            "ARIMA(3, 0, 4) RMSE=0.0010469 MAE=0.0009547\n",
            "ARIMA(3, 1, 1) RMSE=0.0009603 MAE=0.0007205\n",
            "ARIMA(3, 1, 2) RMSE=0.0009692 MAE=0.0007690\n",
            "ARIMA(3, 1, 3) RMSE=0.0009649 MAE=0.0007875\n",
            "ARIMA(3, 1, 4) RMSE=0.0009708 MAE=0.0007380\n",
            "ARIMA(4, 0, 1) RMSE=0.0011438 MAE=0.0010615\n",
            "ARIMA(4, 0, 2) RMSE=0.0010466 MAE=0.0009542\n",
            "ARIMA(4, 0, 3) RMSE=0.0016585 MAE=0.0014407\n",
            "ARIMA(4, 0, 4) RMSE=0.0010466 MAE=0.0009541\n",
            "ARIMA(4, 1, 1) RMSE=0.0008575 MAE=0.0006302\n",
            "ARIMA(4, 1, 2) RMSE=0.0009737 MAE=0.0007952\n",
            "ARIMA(4, 1, 3) RMSE=0.0009399 MAE=0.0007083\n",
            "ARIMA(4, 1, 4) RMSE=0.0010039 MAE=0.0008803\n"
          ]
        }
      ],
      "source": [
        "# HATI-HATI LAMA\n",
        "# Evaluate parameters\n",
        "\n",
        "p_values = [1, 2, 3, 4]\n",
        "d_values = [0, 1]\n",
        "q_values = [1, 2, 3, 4]\n",
        "\n",
        "p, d, q = evaluate_models(y_train, y_test, p_values, d_values, q_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Forecasting Future Values of CPU Usage"
      ],
      "metadata": {
        "id": "5s3wJtSRpx4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(full_data['cpu_used'], order=(p,d,q))\n",
        "model_fit = model.fit()"
      ],
      "metadata": {
        "id": "VAal3M67tppe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of days to be forecasted\n",
        "forecasted_days = 1\n",
        "\n",
        "# Specify the starting timestamp\n",
        "latest_timestamp = full_data.iloc[-1, 0]\n",
        "interval = timedelta(minutes=60)\n",
        "\n",
        "# Specify the number of times to increment the timestamp\n",
        "num_times = int(forecasted_days * 24 * (60/60))\n",
        "\n",
        "# Create an empty list to store the timestamps\n",
        "timestamps = []\n",
        "\n",
        "# Generate the timestamps\n",
        "for i in range(1, num_times+1):\n",
        "    timestamps.append(latest_timestamp + i * interval)"
      ],
      "metadata": {
        "id": "MfzFuVnluhe3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-predict the exiting data with the trained-model\n",
        "fitting = model_fit.predict(start=0, end=len(full_data)-1)\n",
        "\n",
        "\n",
        "# Forecasting new data\n",
        "forecasts = model_fit.forecast(int(forecasted_days * 24 * (60/60))).T\n",
        "\n",
        "# Outputting the forecasted data (NECESSARY DATA [PROBABLY])\n",
        "forecasts = pd.DataFrame({'Timestamp': timestamps, 'Forecasts': forecasts})"
      ],
      "metadata": {
        "id": "gHserfsxr9J_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecasts_json=forecasts.to_json(orient='records')"
      ],
      "metadata": {
        "id": "UP4ogg-aUtcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anomaly Detection"
      ],
      "metadata": {
        "id": "s_pFvq2FHxnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dummy = full_data.copy()\n",
        "df_dummy[\"fittings\"] = fitting\n",
        "df_dummy['Error'] = df_dummy['cpu_used'] - df_dummy['fittings']"
      ],
      "metadata": {
        "id": "TVuWwcN1vHLR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dynamic Thresholding + Consecutive Occurences"
      ],
      "metadata": {
        "id": "ELHQa-QE7bqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy = df_dummy.copy()\n",
        "std_coef = 1.5  # Besar standar deviasi penyimpangan dari mean window\n",
        "window = int(6)  # Windowing\n",
        "consecutive = 3  # Frekuensi minimum kemunculan outliers berturut-turut\n",
        "\n",
        "data_copy['mean'] = pd.Series(data_copy['Error'].rolling(window=window).mean())\n",
        "data_copy['std'] = pd.Series(data_copy['Error'].rolling(window=window).std())\n",
        "data_copy['up_thres'] = pd.Series(data_copy['Error'].rolling(window=window).mean()) \\\n",
        "                    + (std_coef * pd.Series(data_copy['Error'].rolling(window=window).std()))\n",
        "data_copy['down_thres'] = pd.Series(data_copy['Error'].rolling(window=window).mean()) \\\n",
        "                    - (std_coef * pd.Series(data_copy['Error'].rolling(window=window).std()))\n",
        "\n",
        "out_index = data_copy.index[(data_copy['Error'] > data_copy['up_thres']) | (data_copy['Error'] < data_copy['down_thres'])]\n",
        "\n",
        "data_copy['outliers_bool'] = [False for _ in range(len(data_copy))]\n",
        "data_copy['outliers_bool'][out_index] = True"
      ],
      "metadata": {
        "id": "oxVkbKCW7gcW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greater_th = [list(g) for k, g in groupby(data_copy['outliers_bool']==True)]\n",
        "\n",
        "for i in range(len(greater_th)):\n",
        "  if greater_th[i].count(True) < consecutive:\n",
        "    greater_th[i] = [False for _ in greater_th[i]]\n",
        "\n",
        "greater_th = pd.DataFrame({\"Outliers\": [element for sublist in greater_th for element in sublist]})\n",
        "updated_out_index = greater_th[greater_th[\"Outliers\"]==True].index"
      ],
      "metadata": {
        "id": "QFC_8xCr_6_G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_anomaly_labeled = data_copy[['created_at', 'cpu_used']]\n",
        "data_anomaly_labeled['is_anomaly'] = [False for _ in range(len(data_anomaly_labeled))]\n",
        "data_anomaly_labeled['is_anomaly'].iloc[updated_out_index] = True\n",
        "data_anomaly_labeled['cpu_used'] = (data_anomaly_labeled['cpu_used']*100).round(4).astype(str) + \"%\""
      ],
      "metadata": {
        "id": "rbSVbNfgC1wz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Anomaly Labeled Data\n",
        "data_anomaly_labeled.to_csv('anomaly_detection.csv', index=False)"
      ],
      "metadata": {
        "id": "vv1l16chrZLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_anomaly_labeled_json = data_anomaly_labeled.to_json(orient=\"records\")"
      ],
      "metadata": {
        "id": "uG87PfQbXj1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "v2k4AdKVmpBQ",
        "oRES8x0GmpBS",
        "qYmapH9xmpBT",
        "4NkCz6NompBU",
        "DFb0H5cYmpBV",
        "zS_2UZi2mpBW",
        "UltpO8pGmpBX",
        "5TLGmcogmpBz",
        "GdC1T2d1mpB2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}